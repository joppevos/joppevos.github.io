<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on cactus</title>
    <link>https://joppevos.github.io/posts/</link>
    <description>Recent content in Posts on cactus</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Aug 2019 10:36:17 +0200</lastBuildDate>
    
	<atom:link href="https://joppevos.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Pipeline to test Dirty-Data</title>
      <link>https://joppevos.github.io/posts/data-test-pipeline/</link>
      <pubDate>Wed, 28 Aug 2019 10:36:17 +0200</pubDate>
      
      <guid>https://joppevos.github.io/posts/data-test-pipeline/</guid>
      <description>Untested data is dirty Testing on assumptions you have with tests is the standard in software development for decades. In a new field like data science it is not so common, but should be just as important.
Problems do not occur in the database, a database can mostly store whatever you give it. The problems are found way further down stream when the predictions are made and information is already displayed to the client.</description>
    </item>
    
  </channel>
</rss>